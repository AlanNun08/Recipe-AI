name: Comprehensive Test Suite

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - frontend
          - backend
          - e2e

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # Frontend testing job
  frontend-tests:
    if: ${{ github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'frontend' || github.event.inputs.test_type == '' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [18, 20]
        
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'yarn'
          cache-dependency-path: frontend/yarn.lock
          
      - name: Cache node modules
        uses: actions/cache@v3
        with:
          path: frontend/node_modules
          key: ${{ runner.os }}-node-${{ matrix.node-version }}-${{ hashFiles('frontend/yarn.lock') }}
          restore-keys: |
            ${{ runner.os }}-node-${{ matrix.node-version }}-
            
      - name: Install dependencies
        run: |
          cd frontend
          yarn install --frozen-lockfile --prefer-offline
          
      - name: Lint frontend code
        run: |
          cd frontend
          yarn lint --max-warnings=0
          
      - name: Run unit tests
        run: |
          cd frontend
          yarn test --ci --coverage --watchAll=false --maxWorkers=2
          
      - name: Upload frontend coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: frontend/coverage/lcov.info
          flags: frontend
          name: frontend-coverage-${{ matrix.node-version }}
          fail_ci_if_error: false
          
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: frontend-test-results-${{ matrix.node-version }}
          path: |
            frontend/coverage/
            frontend/test-results/
          retention-days: 7

  # Backend testing job
  backend-tests:
    if: ${{ github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'backend' || github.event.inputs.test_type == '' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
        
    services:
      mongodb:
        image: mongo:6.0
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.runCommand({ping: 1})'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
            
      - name: Install dependencies
        run: |
          cd backend
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-asyncio pytest-cov pytest-mock httpx
          
      - name: Lint backend code
        run: |
          cd backend
          pip install black isort flake8
          black --check --diff .
          isort --check-only --diff .
          flake8 . --max-line-length=88 --extend-ignore=E203,W503
          
      - name: Run backend tests
        env:
          MONGO_URL: mongodb://localhost:27017/test_db
          OPENAI_API_KEY: test_key_for_testing
          STRIPE_SECRET_KEY: sk_test_mock_key
          WALMART_CONSUMER_ID: test_consumer_id
          SECRET_KEY: test_secret_key_for_jwt_tokens
        run: |
          cd backend
          pytest tests/ -v --cov=server --cov-report=xml --cov-report=term-missing --junitxml=pytest.xml
          
      - name: Upload backend coverage reports
        uses: codecov/codecov-action@v3
        with:
          file: backend/coverage.xml
          flags: backend
          name: backend-coverage-${{ matrix.python-version }}
          fail_ci_if_error: false
          
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: backend-test-results-${{ matrix.python-version }}
          path: |
            backend/coverage.xml
            backend/pytest.xml
            backend/htmlcov/
          retention-days: 7

  # End-to-end testing job
  e2e-tests:
    if: ${{ github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'e2e' || github.event.inputs.test_type == '' }}
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests]
    
    services:
      mongodb:
        image: mongo:6.0
        ports:
          - 27017:27017
        options: >-
          --health-cmd "mongosh --eval 'db.runCommand({ping: 1})'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install dependencies
        run: |
          # Backend dependencies
          cd backend
          pip install -r requirements.txt
          cd ..
          
          # Frontend dependencies
          cd frontend
          yarn install --frozen-lockfile
          cd ..
          
          # E2E dependencies
          yarn install
          
      - name: Install Playwright browsers
        run: |
          npx playwright install --with-deps chromium firefox webkit
          
      - name: Build frontend
        run: |
          cd frontend
          yarn build
          
      - name: Start services for E2E tests
        run: |
          # Start backend
          cd backend
          python -m uvicorn server:app --host 0.0.0.0 --port 8001 &
          
          # Start frontend
          cd frontend
          npx serve -s build -l 3000 &
          
          # Wait for services to be ready
          sleep 30
          curl -f http://localhost:8001/health || exit 1
          curl -f http://localhost:3000 || exit 1
        env:
          MONGO_URL: mongodb://localhost:27017/test_e2e
          REACT_APP_BACKEND_URL: http://localhost:8001
          OPENAI_API_KEY: test_key_for_e2e
          
      - name: Run E2E tests
        run: |
          npx playwright test --reporter=html --reporter=junit:test-results/results.xml
        env:
          CI: true
          
      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results
          path: |
            playwright-report/
            test-results/
          retention-days: 30
          
      - name: Upload E2E screenshots and videos
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: e2e-failures
          path: |
            test-results/
          retention-days: 7

  # Security testing job
  security-tests:
    if: ${{ github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' }}
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'
          
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
          
      - name: Run npm audit on frontend
        run: |
          cd frontend
          npm audit --audit-level high
          
      - name: Run safety check on backend
        run: |
          cd backend
          pip install safety
          safety check --json --output safety-results.json || true
          
      - name: Upload security scan results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-scan-results
          path: |
            trivy-results.sarif
            backend/safety-results.json
          retention-days: 30

  # Performance testing job
  performance-tests:
    if: ${{ github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' }}
    runs-on: ubuntu-latest
    needs: [e2e-tests]
    
    services:
      mongodb:
        image: mongo:6.0
        ports:
          - 27017:27017
          
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install Artillery
        run: npm install -g artillery@latest
        
      - name: Start application
        run: |
          cd backend
          pip install -r requirements.txt
          python -m uvicorn server:app --host 0.0.0.0 --port 8001 &
          sleep 10
        env:
          MONGO_URL: mongodb://localhost:27017/perf_test_db
          OPENAI_API_KEY: test_key_for_performance
          
      - name: Run performance tests
        run: |
          artillery run tests/performance/load-test.yml --output performance-report.json
          
      - name: Upload performance results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-test-results
          path: |
            performance-report.json
            artillery_report_*.html
          retention-days: 7

  # Build and package job
  build-and-package:
    if: ${{ github.event.inputs.test_type == 'all' || github.event.inputs.test_type == '' }}
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'yarn'
          cache-dependency-path: frontend/yarn.lock
          
      - name: Build frontend
        run: |
          cd frontend
          yarn install --frozen-lockfile
          yarn build
          
      - name: Create deployment package
        run: |
          mkdir -p deployment-package
          cp -r frontend/build deployment-package/frontend
          cp -r backend deployment-package/backend
          cp -r docs deployment-package/docs
          tar -czf deployment-package.tar.gz deployment-package/
          
      - name: Upload deployment package
        uses: actions/upload-artifact@v3
        with:
          name: deployment-package
          path: deployment-package.tar.gz
          retention-days: 30

  # Summary job
  test-summary:
    if: always()
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests, e2e-tests, security-tests, performance-tests, build-and-package]
    
    steps:
      - name: Generate test summary
        run: |
          echo "# Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Job Results" >> $GITHUB_STEP_SUMMARY
          echo "- Frontend Tests: ${{ needs.frontend-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Backend Tests: ${{ needs.backend-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- E2E Tests: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Security Tests: ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Build & Package: ${{ needs.build-and-package.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Overall Status" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ needs.frontend-tests.result }}" == "success" && "${{ needs.backend-tests.result }}" == "success" && "${{ needs.e2e-tests.result }}" == "success" ]]; then
            echo "✅ All core tests passed successfully!" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Some tests failed. Please check the individual job logs." >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Fail workflow if critical tests failed
        if: ${{ needs.frontend-tests.result == 'failure' || needs.backend-tests.result == 'failure' || needs.e2e-tests.result == 'failure' }}
        run: |
          echo "Critical tests failed. Failing the workflow."
          exit 1